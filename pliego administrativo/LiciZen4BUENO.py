#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os, re, json
from pathlib import Path
from collections import defaultdict
from hashlib import sha1
from dotenv import load_dotenv
from langchain.schema import Document
from langchain_core.chat_history import InMemoryChatMessageHistory
from langchain_core.messages import HumanMessage, AIMessage
from langchain_core.prompts import ChatPromptTemplate, PromptTemplate
from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings
from langchain_qdrant import Qdrant
import qdrant_client
from qdrant_client.http import models as qmodels
from langchain.chains import LLMChain
from langchain_core.runnables import RunnableMap
from langchain.memory import ConversationBufferMemory


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 0.â€¯Variables de entorno
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
load_dotenv()
API_KEY        = os.getenv("GOOGLE_API_KEY")
QDRANT_API_KEY = os.getenv("QDRANT_API_KEY")
QDRANT_URL     = os.getenv("QDRANT_URL")

COLLECTION_NAME = "Prevencion_de_blanqueo_y_finanzas_sensibles"

# â”€â”€â”€ CAMBIO â”€â”€â”€ directorio de PDFs (no JSON)
PDF_DIR = "/home/reboot-student/Desktop/Licitacion/docs/leyes/a"

emb = GoogleGenerativeAIEmbeddings(model="models/embedding-001", google_api_key=API_KEY)
client = qdrant_client.QdrantClient(url=QDRANT_URL, api_key=QDRANT_API_KEY)

COLLECTIONS_SEARCH = [
    " Normativa General y ContrataciÃ³n PÃºblica",
    "proteccion_de_datos_y_seguridad_digital",
    "sostenibilidad_recuperacion_y_fondos_europeos"
]

vectorstores = {
    name: Qdrant(
        client=client,
        collection_name=name,
        embeddings=emb
    )
    for name in COLLECTIONS_SEARCH
}
def contexto_multi_colecciones(query: str, k: int = 10) -> str:
    """
    Recorre cada colecciÃ³n, extrae los k documentos mÃ¡s similares
    y devuelve un string combinando todo, marcado por cabeceras.
    """
    bloques = []
    for nombre, store in vectorstores.items():
        docs = store.similarity_search(query, k=k)
        if not docs:
            continue
        # Â­â”† Opcional: podrÃ­as resumir aquÃ­ cada bloque con el LLM si pesa demasiado
        bloque = "\n".join(d.page_content for d in docs)
        bloques.append(f"### {nombre}\n{bloque}")
    return "\n\n".join(bloques)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 1.â€¯Historial
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
history = InMemoryChatMessageHistory()
def construir_historial_chat(msgs):
    partes = []
    for m in msgs[-6:]:
        pref = "Humano: " if isinstance(m, HumanMessage) else "Asistente: "
        partes.append(pref + m.content)
    return "\n".join(partes)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 2â€‘3.â€¯LLM base y chat casual
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
llm = ChatGoogleGenerativeAI(model="gemini-2.5-flash", temperature=0.5)
chat_chain = (
    ChatPromptTemplate.from_messages(
        [("system", "Eres un asistente de IA amistoso y Ãºtil."),
         ("human", "{question}")]
    )
    | llm
)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 4.â€¯Carga y troceo de artÃ­culos DESDE PDF
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
from langchain_community.document_loaders import PyPDFLoader            # â”€â”€â”€ CAMBIO â”€â”€â”€

# â”€â”€â”€ CAMBIO â”€â”€â”€: patrones y helpers para dividir PDFs en artÃ­culos
REG_TITULO_LINEA = re.compile(
    r'^\s*(?:ArtÃ­culo\s+\d+[\.\)\-:]?\s+.+?|'
    r'DisposiciÃ³n\s+(?:adicional|transitoria|derogatoria|final)\s+\d*[A-Z]?[\.\)\-:]?.*?|'
    r'PreÃ¡mbulo|ExposiciÃ³n\s+de\s+motivos|Anexo\s+\w+.*?)\s*$',
    re.IGNORECASE
)
REG_ARTICULO_INLINE = re.compile(
    r'\bArtÃ­culo\s+\d+[\.\)\-:]?\s+[A-ZÃÃ‰ÃÃ“ÃšÃœÃ‘][^\n]*',
    re.IGNORECASE
)

def split_inline_articulos(texto, pagina, titulo_padre):
    mats = list(REG_ARTICULO_INLINE.finditer(texto))
    if not mats:
        return [{"titulo": titulo_padre or "(sin tÃ­tulo)",
                 "contenido": texto.strip(), "pagina": pagina}]
    bloques = []
    for i, m in enumerate(mats):
        inicio = m.end()
        fin    = mats[i+1].start() if i+1<len(mats) else len(texto)
        titulo = titulo_padre if i==0 and titulo_padre else m.group(0).strip()
        bloques.append({"titulo": titulo,
                        "contenido": texto[inicio:fin].strip(),
                        "pagina": pagina})
    return bloques

def procesar_pdf(ruta_pdf: Path):
    loader  = PyPDFLoader(str(ruta_pdf))
    paginas = loader.load()

    bloques, bloque = [], {"titulo": None, "contenido": "", "pagina": None}

    for doc in paginas:
        pagina = doc.metadata.get("page")
        for linea in (doc.page_content or "").splitlines():
            linea = linea.strip()
            if not linea: 
                continue
            if REG_TITULO_LINEA.match(linea):
                if bloque["titulo"] and bloque["contenido"].strip():
                    bloques.extend(
                        split_inline_articulos(bloque["contenido"],
                                               bloque["pagina"],
                                               bloque["titulo"])
                    )
                bloque = {"titulo": linea, "contenido": "", "pagina": pagina}
            else:
                bloque["contenido"] += linea + "\n"

    if bloque["titulo"] and bloque["contenido"].strip():
        bloques.extend(
            split_inline_articulos(bloque["contenido"],
                                   bloque["pagina"],
                                   bloque["titulo"])
        )
    return bloques

# â”€â”€â”€ FIN helpers PDF â”€â”€â”€

def split_articulo_en_partes(titulo, texto, pagina, max_chars=1800):
    buffer, partes, idx = f"{titulo}\n", [], 1
    for p in texto.splitlines():
        p = p.strip()
        if not p: continue
        if len(buffer) + len(p) < max_chars:
            buffer += p + "\n"
        else:
            partes.append(
                Document(
                    page_content=f"[PÃ¡gina {pagina}]\n{titulo}\n(Parte {idx})\n{buffer.strip()}",
                    metadata={"titulo": titulo, "parte": idx, "page": pagina}
                )
            )
            idx, buffer = idx + 1, p + "\n"
    if buffer.strip():
        partes.append(
            Document(
                page_content=f"[PÃ¡gina {pagina}]\n{titulo}\n(Parte {idx})\n{buffer.strip()}",
                metadata={"titulo": titulo, "parte": idx, "page": pagina}
            )
        )
    return partes

# â”€â”€â”€ CAMBIO â”€â”€â”€: carga chunks directamente desde los PDF
def cargar_chunks_desde_pdfs(carpeta):
    chunks = []
    for path in Path(carpeta).glob("*.pdf"):
        for entrada in procesar_pdf(path):
            for p in split_articulo_en_partes(
                entrada["titulo"], entrada["contenido"], entrada["pagina"]
            ):
                p.metadata["source"] = path.name
                chunks.append(p)
    return chunks

def agrupar_chunks_por_titulo(chs):
    grupos = defaultdict(list)
    for d in chs:
        grupos[d.metadata["titulo"]].append(d)
    fusion = []
    for titulo, docs in grupos.items():
        docs.sort(key=lambda d: d.metadata.get("parte", 0))
        fusion.append(
            Document(
                page_content="\n".join(d.page_content for d in docs),
                metadata=docs[0].metadata,
            )
        )
    return fusion

# â”€â”€â”€ CAMBIO â”€â”€â”€
chunks = cargar_chunks_desde_pdfs(PDF_DIR)

# Ãndice auxiliar â†’  nÃºmero de artÃ­culo  â†’ [chunks]
idx_por_num = defaultdict(list)
pat_num = re.compile(r"\b(\d+)\b")
for c in chunks:
    if m := pat_num.search(c.metadata["titulo"]):
        idx_por_num[m.group(1)].append(c)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 7.â€¯Embeddings y Qdrant
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# if client.collection_exists(COLLECTION_NAME):
#     client.delete_collection(COLLECTION_NAME)

# client.create_collection(
#     COLLECTION_NAME,
#     vectors_config=qmodels.VectorParams(size=768, distance=qmodels.Distance.COSINE),
# )
vectorstore = Qdrant(client=client, collection_name=COLLECTION_NAME, embeddings=emb)

# vectorstore.add_documents(chunks)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 8.â€¯Cadena RAG
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
rag_prompt = PromptTemplate.from_template(
    "Eres un experto redactor de licitaciones pÃºblicas en EspaÃ±a, especializado en la elaboraciÃ³n de pliegos de clÃ¡usulas administrativas particulares. "
    "Tu tarea es redactar, desde cero, un pliego completo y tÃ©cnicamente riguroso para un contrato de servicios informÃ¡ticos (CPV 72500000). "
    "Debes utilizar un lenguaje jurÃ­dico-administrativo preciso, estructurado conforme a la normativa vigente en EspaÃ±a.\n\n"
    "Debes fundamentarte especialmente en la Ley 9/2017, de 8 de noviembre, de Contratos del Sector PÃºblico, y citar los artÃ­culos relevantes "
    "en cada apartado (por ejemplo: objeto del contrato, procedimiento de adjudicaciÃ³n, criterios de solvencia, garantÃ­as, etc.). "
    "TambiÃ©n puedes apoyarte en otras normas complementarias o guÃ­as oficiales cuando sea adecuado.\n\n"
    "Utiliza la documentaciÃ³n proporcionada como soporte y referencia directa, y ten en cuenta el historial del chat para mantener la coherencia del contenido.\n\n"
    "Historial del chat:\n{chat_history}\n\n"
    "DocumentaciÃ³n de apoyo:\n{context}\n\n"
    "InstrucciÃ³n o pregunta especÃ­fica:\n{question}"
)
doc_chain = LLMChain(llm=llm, prompt=rag_prompt)
qa_chain = RunnableMap({
    "context":     lambda x: vectorstore.similarity_search(x["query"], k=25),
    "question":    lambda x: x["query"],
    "chat_history":lambda x: x["chat_history"],
}) | doc_chain

def preguntar_datos():
    print("ğŸ“ Vamos a generar una licitaciÃ³n personalizada. Contesta las siguientes preguntas:\n")

    datos = {}

    # 1. Datos del contrato
    print("ğŸŸ¢ 1. DATOS DEL CONTRATO")
    datos["objeto_contrato"] = input("Â¿CuÃ¡l es el objeto del contrato? ")
    datos["necesidad_resuelta"] = input("Â¿QuÃ© necesidad resuelve este servicio? ")
    datos["responsable_contrato"] = input("Â¿QuiÃ©n serÃ¡ el responsable del contrato (nombre y cargo)? ")
    datos["lugar_prestacion"] = input("Â¿DÃ³nde se prestarÃ¡ el servicio? ")

    # 2. Presupuesto
    print("\nğŸ’° 2. PRESUPUESTO")
    datos["pbl_sin_iva"] = input("Â¿CuÃ¡l es el presupuesto base sin IVA? ")
    datos["iva"] = input("Â¿CuÃ¡l es el porcentaje de IVA aplicable? ")
    datos["prorrogas"] = input("Â¿Hay prÃ³rrogas previstas? Â¿De cuÃ¡ntos meses? ")

    # 3. Empresa licitadora
    print("\nğŸ“„ 3. EMPRESA LICITADORA")
    datos["nombre_empresa"] = input("Â¿Nombre de la empresa? ")
    datos["cif"] = input("Â¿CIF? ")
    datos["domicilio_fiscal"] = input("Â¿Domicilio fiscal? ")
    datos["persona_contacto"] = input("Â¿Nombre y correo de la persona de contacto? ")
    datos["censo_aeat"] = input("Â¿EstÃ¡ inscrita la empresa en el Censo de empresarios de la AEAT? ")

    # 4. DocumentaciÃ³n
    print("\nğŸ” 4. DOCUMENTACIÃ“N Y REQUISITOS")
    datos["declaracion_responsable"] = input("Â¿PresentarÃ¡s la DeclaraciÃ³n Responsable? ")
    datos["oferta_economica"] = input("Â¿Tienes oferta econÃ³mica lista? ")
    datos["acepta_pliego"] = input("Â¿Aceptas las condiciones del pliego tÃ©cnico? ")
    datos["perfiles_equipo"] = input("Â¿Tu equipo cumple los perfiles mÃ­nimos exigidos? ")

    # 5. ProtecciÃ³n de datos
    print("\nğŸ”’ 5. PROTECCIÃ“N DE DATOS")
    datos["trata_datos"] = input("Â¿TratarÃ¡s datos personales por cuenta del contratante? ").strip().lower()
    if datos["trata_datos"] in ["sÃ­", "si", "s"]:
        datos["subcontrata_tratamiento"] = input("Â¿SubcontratarÃ¡s servidores o servicios de tratamiento? ")
    else:
        datos["subcontrata_tratamiento"] = None

    # 6. SubcontrataciÃ³n
    print("\nğŸ“¦ 6. SUBCONTRATACIÃ“N")
    datos["subcontratacion"] = input("Â¿Vas a subcontratar alguna parte del servicio? ").strip().lower()
    if datos["subcontratacion"] in ["sÃ­", "si", "s"]:
        datos["empresas_vinculadas"] = input("Â¿Tus subcontratistas son empresas no vinculadas? ")
    else:
        datos["empresas_vinculadas"] = None

    # 7. Criterios de valoraciÃ³n
    print("\nğŸ“‰ 7. CRITERIOS DE VALORACIÃ“N")
    datos["precio_ofertado"] = input("Â¿CuÃ¡l es tu precio ofertado (sin IVA)? ")
    datos["precio_anormal"] = input("Â¿Has revisado que no sea anormalmente bajo? ")

    # 8. PRTR / NextGen
    print("\nğŸ§¾ 8. NEXTGENERATION / PRTR")
    datos["cumple_prtr"] = input("Â¿Cumples con principios medioambientales y antifraude del PRTR? (sÃ­/no): ").strip().lower()
    if datos["cumple_prtr"] in ["sÃ­", "si", "s"]:
        datos["modelos_b1_b2_c"] = input("Â¿Has rellenado los modelos B1, B2 y C? ")
        datos["titular_real"] = input("Â¿QuiÃ©n es el titular real de la empresa? ")
    else:
        datos["modelos_b1_b2_c"] = None
        datos["titular_real"] = None

    return datos


def generar_licitacion(datos):
    print("\nğŸ“„ RESUMEN DE LICITACIÃ“N GENERADO:\n")

    texto = f"""
ğŸ”¹ Objeto del contrato:
{datos['objeto_contrato']}

ğŸ”¹ Necesidad que se pretende resolver:
{datos['necesidad_resuelta']}

ğŸ”¹ Lugar de prestaciÃ³n del servicio:
{datos['lugar_prestacion']}

ğŸ”¹ Persona responsable del contrato:
{datos['responsable_contrato']}

ğŸ”¹ Presupuesto base (sin IVA): {datos['pbl_sin_iva']} â‚¬
ğŸ”¹ IVA aplicable: {datos['iva']}%
ğŸ”¹ PrÃ³rrogas previstas: {datos['prorrogas']}

ğŸ”¹ Empresa licitadora:
Nombre: {datos['nombre_empresa']}
CIF: {datos['cif']}
Domicilio fiscal: {datos['domicilio_fiscal']}
Persona de contacto: {datos['persona_contacto']}
Inscrita en el censo AEAT: {datos['censo_aeat']}

ğŸ”¹ DocumentaciÃ³n y requisitos:
- DeclaraciÃ³n Responsable: {datos['declaracion_responsable']}
- Oferta EconÃ³mica: {datos['oferta_economica']}
- AceptaciÃ³n del Pliego TÃ©cnico: {datos['acepta_pliego']}
- Perfiles del equipo: {datos['perfiles_equipo']}
"""

    # ProtecciÃ³n de datos (condicional)
    if datos["trata_datos"] in ["sÃ­", "si", "s"]:
        texto += f"""
ğŸ”¹ ProtecciÃ³n de datos:
- Â¿TratarÃ¡ datos personales?: SÃ­
- Â¿SubcontratarÃ¡ tratamiento?: {datos['subcontrata_tratamiento']}
"""
    else:
        texto += "\nğŸ”¹ ProtecciÃ³n de datos: No se tratarÃ¡n datos personales.\n"

    # SubcontrataciÃ³n (condicional)
    if datos["subcontratacion"] in ["sÃ­", "si", "s"]:
        texto += f"""
ğŸ”¹ SubcontrataciÃ³n:
- Â¿Se subcontrata parte del servicio?: SÃ­
- Empresas no vinculadas: {datos['empresas_vinculadas']}
"""
    else:
        texto += "\nğŸ”¹ SubcontrataciÃ³n: No se prevÃ© subcontrataciÃ³n.\n"

    # Oferta econÃ³mica
    texto += f"""
ğŸ”¹ Oferta econÃ³mica:
- Precio ofertado: {datos['precio_ofertado']} â‚¬
- RevisiÃ³n de precio anormalmente bajo: {datos['precio_anormal']}
"""

    # PRTR (condicional)
    if datos["cumple_prtr"] in ["sÃ­", "si", "s"]:
        texto += f"""
ğŸ”¹ FinanciaciÃ³n NextGeneration / PRTR:
- Cumple principios PRTR: SÃ­
- Modelos B1, B2 y C: {datos['modelos_b1_b2_c']}
- Titular real de la empresa: {datos['titular_real']}
"""

    print(texto)



def construir_pregunta_final(respuestas):
    texto = "Quiero generar una licitaciÃ³n pÃºblica con los siguientes datos:\n\n"

    for clave, valor in respuestas.items():
        texto += f"- {clave.replace('_', ' ').capitalize()}: {valor}\n"

    texto += "\nRedacta la licitaciÃ³n completa con lenguaje tÃ©cnico y formato oficial."
    return texto


if __name__ == "__main__":
    respuestas = preguntar_datos()

    query = construir_pregunta_final(respuestas)
    hist = construir_historial_chat(history.messages)
    contexto = contexto_multi_colecciones(query, k=25)   # ajusta k a tu gusto


    out = doc_chain.invoke({
        "question": query,
        "chat_history": hist,
        "context": contexto
    })

    answer = out["text"] if isinstance(out, dict) else out
    print("\nğŸ“„ LICITACIÃ“N GENERADA POR IA:\n")
    print(answer)

    history.add_user_message(query)
    history.add_ai_message(answer)



# â”€â”€â”€ DEBUG â”€â”€â”€
DEBUG_SHOW_CONTEXT = True
def resumen_docs(documents):
    lineas = []
    for d in documents:
        meta = d.metadata
        lineas.append(
            f"{meta.get('source','?')} | {meta.get('titulo')[:60]} "
            f"(parte {meta.get('parte','?')}, pÃ¡g. {meta.get('page','?')})"
        )
    return "\n".join(lineas)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 9.â€¯Bucle principal
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
print("ğŸ¤–  Geminiâ€¯RAG activo.  'salir' para terminar.\n")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 9. Bucle principal interactivo
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
print("ğŸ¤–  Gemini RAG activo.  Escribe 'licitacion' para generar un pliego, 'salir' para terminar.\n")

while True:
    query = input("\nTÃº: ").strip()
    if not query:
        continue

    lower_q = query.lower()

    # --- Salida ---
    if lower_q == "salir":
        print("ğŸ«‚  Â¡Hasta luego!")
        break

    # --- Modo generaciÃ³n de licitaciÃ³n completa ---
    if lower_q == "licitacion":
        respuestas = preguntar_datos()
        query = construir_pregunta_final(respuestas)   # esto es la pregunta real al RAG

        # construimos contexto desde TODAS las colecciones
        contexto = contexto_multi_colecciones(query, k=10)
        hist     = construir_historial_chat(history.messages)

        out = doc_chain.invoke({"question": query, "chat_history": hist, "context": contexto})
        answer = out["text"] if isinstance(out, dict) else out

        print("\nğŸ“„ LICITACIÃ“N GENERADA POR IA:\n")
        print(answer)

        history.add_user_message(query)
        history.add_ai_message(answer)
        continue   # seguimos en el loop

    try:
        # --- Consulta normal ---
        # Si el usuario menciona un nÃºmero que coincide con tu Ã­ndice local por artÃ­culo,
        # prioriza ese match hiper-preciso de la colecciÃ³n reciÃ©n cargada en memoria.
        num_match = re.search(r"\b(\d+)\b", query)
        if num_match and num_match.group(1) in idx_por_num:
            rel = idx_por_num[num_match.group(1)]
            rel.sort(key=lambda d: d.metadata.get("parte", 0))
            matches_docs = agrupar_chunks_por_titulo(rel)
            contexto = "\n\n".join(d.page_content for d in matches_docs)
        else:
            # Si no hay match directo â†’ buscar en TODAS las colecciones Qdrant
            contexto = contexto_multi_colecciones(query, k=8)

        if contexto.strip():
            hist = construir_historial_chat(history.messages)
            out = doc_chain.invoke({"question": query, "chat_history": hist, "context": contexto})
            answer = out["text"] if isinstance(out, dict) else out

            print("\nğŸ“„  RAG:\n" + answer + "\n")

            history.add_user_message(query)
            history.add_ai_message(answer)
        else:
            # Fallback chat sin RAG
            resp = chat_chain.invoke({"question": query})
            print("\nğŸ—£ï¸  Chat:\n" + resp.content + "\n")
            history.add_user_message(query)
            history.add_ai_message(resp.content)

    except Exception as e:
        print("âš ï¸  Error en el loop:", e)
